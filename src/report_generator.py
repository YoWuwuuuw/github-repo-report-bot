from __future__ import annotations

from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import List, Optional

from .analyzer import IssueAnalysis, PRAnalysis, DiscussionAnalysis

# åŒ—äº¬æ—¶é—´æ—¶åŒºï¼ˆUTC+8ï¼‰
BEIJING_TZ = timezone(timedelta(hours=8))


def _ts() -> str:
    return datetime.now(timezone.utc).astimezone(BEIJING_TZ).strftime("%Y-%m-%d %H:%M:%S") + " (åŒ—äº¬æ—¶é—´)"


def generate_markdown_report(
    repo_full_name: str,
    issues: List[IssueAnalysis],
    prs: List[PRAnalysis],
    discussions: List[DiscussionAnalysis],
    report_dir: Path,
    period: str = "day",
    period_label: str = "",
    period_start: Optional[datetime] = None,
    period_end: Optional[datetime] = None,
) -> Path:
    report_dir.mkdir(parents=True, exist_ok=True)
    ts_slug = datetime.now(timezone.utc).strftime("%Y%m%d-%H%M%S")
    report_path = report_dir / f"report-{ts_slug}.md"

    lines: list[str] = []
    period_display = "æ¯æ—¥" if period == "day" else "æ¯å‘¨"
    lines.append(f"# {period_display}åˆ†ææŠ¥å‘Š - {repo_full_name}")
    lines.append("")
    lines.append(f"- **ç”Ÿæˆæ—¶é—´**: {_ts()}")
    if period_label:
        lines.append(f"- **æ—¶é—´ç»´åº¦**: {period_label}")
    if period_start and period_end:
        period_start_bj = period_start.astimezone(BEIJING_TZ)
        period_end_bj = period_end.astimezone(BEIJING_TZ)
        lines.append(f"- **æ—¶é—´èŒƒå›´**: {period_start_bj.strftime('%Y-%m-%d %H:%M:%S')} è‡³ {period_end_bj.strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)")
    lines.append(f"- **Issue æ•°é‡**: {len(issues)}")
    lines.append(f"- **PR æ•°é‡**: {len(prs)}")
    lines.append(f"- **Discussion æ•°é‡**: {len(discussions)}")
    lines.append("")

    if prs:
        lines.append("## Pull Request æ¦‚è¦")
        lines.append("")
        lines.append(
            "| ç¼–å· | æ ‡é¢˜ | ä½œè€… | ç±»å‹ | ä¼˜å…ˆçº§ | è§„æ¨¡ | æ€»åˆ† | è¯„çº§ | çŠ¶æ€ |"
        )
        lines.append(
            "| --- | --- | --- | --- | --- | --- | --- | --- | --- |"
        )
        for pr in sorted(prs, key=lambda x: x.total_score, reverse=True):
            lines.append(
                f"| PR-{pr.number} | {pr.title[:40]} | {pr.author} | {pr.pr_type} | "
                f"{pr.priority} | {pr.size_category} | {pr.total_score} | {pr.rating} | {pr.state} |"
            )
        lines.append("")

    if issues:
        lines.append("## Issue æ¦‚è¦")
        lines.append("")
        lines.append(
            "| ç¼–å· | æ ‡é¢˜ | ä½œè€… | çŠ¶æ€ | åˆ†ç±» | è¯„è®ºæ•° | åˆ›å»ºæ—¶é—´ |"
        )
        lines.append(
            "| --- | --- | --- | --- | --- | --- | --- |"
        )
        for it in issues:
            lines.append(
                f"| Issue-{it.number} | {it.title[:40]} | {it.author} | {it.state} | "
                f"{it.category} | {it.comments} | {it.created_at[:10]} |"
            )
        lines.append("")

    if prs:
        lines.append("## PR è¯¦ç»†åˆ†æ")
        for pr in sorted(prs, key=lambda x: x.total_score, reverse=True):
            lines.append("")
            lines.append(f"### PR-{pr.number} - {pr.title}")
            lines.append("")
            lines.append(f"- ä½œè€…ï¼š{pr.author}")
            lines.append(f"- çŠ¶æ€ï¼š{pr.state}ï¼ˆmerged: {bool(pr.merged_at)}ï¼‰")
            lines.append(f"- åˆ›å»ºæ—¶é—´ï¼š{pr.created_at}")
            lines.append(f"- å˜æ›´æ–‡ä»¶æ•°ï¼š{pr.changed_files}")
            lines.append(f"- æ–°å¢ / åˆ é™¤è¡Œï¼š+{pr.additions} / -{pr.deletions}")
            lines.append(f"- æäº¤æ¬¡æ•°ï¼š{pr.commits}")
            lines.append(f"- ç±»å‹ï¼š{pr.pr_type}ï¼Œä¼˜å…ˆçº§ï¼š{pr.priority}")
            lines.append(f"- è§„æ¨¡ï¼š{pr.size_category}")
            lines.append("")
            lines.append("**ç»´åº¦è¯„åˆ†ï¼ˆ0-10ï¼‰ï¼š**")
            lines.append(
                f"- æäº¤ç±»å‹ï¼š{pr.type_score}"
            )
            lines.append(f"- æ”¹åŠ¨è§„æ¨¡ï¼š{pr.size_score}")
            lines.append(f"- ä»£ç è´¨é‡ï¼š{pr.code_quality_score}")
            lines.append(f"- æµ‹è¯•è¦†ç›–ç‡ï¼š{pr.test_coverage_score}")
            lines.append(
                f"- æ–‡æ¡£ä¸å¯ç»´æŠ¤æ€§ï¼š{pr.doc_maintain_score}"
            )
            lines.append(
                f"- åˆè§„ä¸å®‰å…¨ï¼š{pr.compliance_security_score}"
            )
            lines.append(f"- å½±å“èŒƒå›´åˆç†æ€§ï¼š{pr.merge_history_score}")
            lines.append(f"- PRä»·å€¼ä¸ä½œç”¨ï¼š{pr.collaboration_score}")
            lines.append("")
            lines.append(f"**ç»¼åˆè¯„åˆ†ï¼š{pr.total_score} ï¼ˆ{pr.rating}ï¼‰**")
            lines.append("")
            if pr.qwen_comment:
                lines.append("**Qwen å»ºè®®ï¼š**")
                lines.append("")
                lines.append(pr.qwen_comment)
                lines.append("")

    if issues:
        lines.append("## Issue è¯¦ç»†åˆ—è¡¨")
        for it in issues:
            lines.append("")
            lines.append(f"### Issue-{it.number} - {it.title}")
            lines.append("")
            lines.append(f"- ä½œè€…ï¼š{it.author}")
            lines.append(f"- çŠ¶æ€ï¼š{it.state}")
            lines.append(f"- åˆ†ç±»ï¼š{it.category}")
            lines.append(f"- æ ‡ç­¾ï¼š{', '.join(it.labels) if it.labels else 'æ— '}")
            lines.append(f"- è¯„è®ºæ•°ï¼š{it.comments}")
            lines.append(f"- åˆ›å»ºæ—¶é—´ï¼š{it.created_at}")
            if it.closed_at:
                lines.append(f"- å…³é—­æ—¶é—´ï¼š{it.closed_at}")
            lines.append("")
            lines.append(f"æ‘˜è¦ï¼š{it.summary}")

    if discussions:
        lines.append("## Discussion è¯¦ç»†åˆ—è¡¨")
        # åŒºåˆ†æ—¶é—´æ®µå†…åˆ›å»ºçš„ Discussion å’Œæœ‰åŠ¨é™çš„ Discussion
        created_discussions = [d for d in discussions if d.created_in_period]
        updated_discussions = [d for d in discussions if not d.created_in_period]

        if created_discussions:
            lines.append("")
            lines.append("### ğŸ“… æ—¶é—´æ®µå†…åˆ›å»ºçš„ Discussion")
            for disc in sorted(created_discussions, key=lambda x: x.number, reverse=True):
                lines.append("")
                lines.append(f"### Discussion-{disc.number} - {disc.title}")
                lines.append("")
                lines.append(f"- ä½œè€…ï¼š{disc.author}")
                lines.append(f"- çŠ¶æ€ï¼š{disc.state}")
                lines.append(f"- åˆ†ç±»ï¼š{disc.category}")
                lines.append(f"- æ ‡ç­¾ï¼š{', '.join(disc.labels) if disc.labels else 'æ— '}")
                lines.append(f"- è¯„è®ºæ•°ï¼š{disc.comments}")
                lines.append(f"- åˆ›å»ºæ—¶é—´ï¼š{disc.created_at}")
                if disc.updated_at:
                    lines.append(f"- æ›´æ–°æ—¶é—´ï¼š{disc.updated_at}")
                lines.append("")
                lines.append(f"æ‘˜è¦ï¼š{disc.summary}")
                if disc.ai_summary:
                    lines.append(f"AI æ‘˜è¦ï¼š{disc.ai_summary}")

        if updated_discussions:
            lines.append("")
            lines.append("### ğŸ”„ æ—¶é—´æ®µå†…æœ‰åŠ¨é™çš„ Discussion")
            for disc in sorted(updated_discussions, key=lambda x: x.number, reverse=True):
                lines.append("")
                lines.append(f"### Discussion-{disc.number} - {disc.title}")
                lines.append("")
                lines.append(f"- ä½œè€…ï¼š{disc.author}")
                lines.append(f"- çŠ¶æ€ï¼š{disc.state}")
                lines.append(f"- åˆ†ç±»ï¼š{disc.category}")
                lines.append(f"- æ ‡ç­¾ï¼š{', '.join(disc.labels) if disc.labels else 'æ— '}")
                lines.append(f"- è¯„è®ºæ•°ï¼š{disc.comments}")
                lines.append(f"- åˆ›å»ºæ—¶é—´ï¼š{disc.created_at}")
                if disc.updated_at:
                    lines.append(f"- æ›´æ–°æ—¶é—´ï¼š{disc.updated_at}")
                lines.append("")
                lines.append(f"æ‘˜è¦ï¼š{disc.summary}")
                if disc.ai_summary:
                    lines.append(f"AI æ‘˜è¦ï¼š{disc.ai_summary}")

    report_path.write_text("\n".join(lines), encoding="utf-8")
    return report_path




